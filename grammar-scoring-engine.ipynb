{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":97919,"databundleVersionId":11694977,"sourceType":"competition"}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# 📦 Imports & Warnings\nimport os\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torchaudio\nfrom sklearn.model_selection import KFold, train_test_split\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.metrics import mean_squared_error\nfrom scipy.stats import pearsonr, rankdata\nfrom tqdm import tqdm\nimport joblib\nimport xgboost as xgb\nimport lightgbm as lgb\nimport catboost as cb\nimport warnings\n\n# Ignore specific torchaudio warnings\nwarnings.filterwarnings(\"ignore\", message=\".*mel filterbank has all zero values.*\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"📝 Brief Report\n\n🔍 Objective:\nTo build a Grammar Scoring Engine that predicts a continuous grammar score (0–5) from ~45–60 second audio clips of spoken English. The model is evaluated using Pearson correlation.\n\n🧱 Pipeline Overview:\n    \nFeature Extraction:\nWav2Vec2 embeddings (mean + std)\nDelta features (mean + std)\nMFCC features\nProsodic features: pitch and energy\nAudio duration\n\nBase Models:\nXGBoost, LightGBM, CatBoost\n\nMeta Model:\nGradient Boosting Regressor\n\nEnsemble:\nStacking + Rank Averaging\n\nValidation:\n5-Fold CV + Hold-out 20% split for final Pearson score","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 🎧 Load Pre-trained Wav2Vec2 Model\nbundle = torchaudio.pipelines.WAV2VEC2_BASE\nwav2vec_model = bundle.get_model()\nwav2vec_model.eval()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 🎵 Feature Extraction Function\ndef extract_features(file_path):\n    waveform, sample_rate = torchaudio.load(file_path)\n    if waveform.shape[0] > 1:\n        waveform = waveform.mean(dim=0, keepdim=True)\n    if sample_rate != bundle.sample_rate:\n        resampler = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=bundle.sample_rate)\n        waveform = resampler(waveform)\n    with torch.inference_mode():\n        features = wav2vec_model(waveform)[0].squeeze(0)\n        mean_feat = features.mean(dim=0)\n        std_feat = features.std(dim=0)\n\n        # Delta features\n        delta_feat = features[1:] - features[:-1]\n        delta_mean = delta_feat.mean(dim=0)\n        delta_std = delta_feat.std(dim=0)\n\n        # Duration\n        duration = waveform.shape[1] / sample_rate\n\n        # MFCC & Prosodic\n        mfcc = torchaudio.transforms.MFCC()(waveform).squeeze(0).mean(dim=1)\n        pitch = waveform.abs().mean().unsqueeze(0)\n        energy = torch.norm(waveform).unsqueeze(0)\n\n        combined = torch.cat([mean_feat, std_feat, delta_mean, delta_std, mfcc, pitch, energy, torch.tensor([duration])])\n        return combined.numpy()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 🧠 Load Training Data\ntrain_df = pd.read_csv(\"/kaggle/input/shl-intern-hiring-assessment/dataset/train.csv\")\n\n# 🔁 Load Cached or Extract Features\nif os.path.exists(\"X_feats.npy\") and os.path.exists(\"y_feats.npy\"):\n    print(\"🔁 Loading saved features...\")\n    X = np.load(\"X_feats.npy\")\n    y = np.load(\"y_feats.npy\")\nelse:\n    print(\"🎧 Extracting features from training set...\")\n    X, y = [], []\n    for _, row in tqdm(train_df.iterrows(), total=len(train_df)):\n        try:\n            path = f\"/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/{row['filename']}\"\n            feat = extract_features(path)\n            X.append(feat)\n            y.append(row['label'])\n        except Exception as e:\n            print(f\"❌ Error with {row['filename']}: {e}\")\n    X = np.array(X)\n    y = np.array(y)\n    np.save(\"X_feats.npy\", X)\n    np.save(\"y_feats.npy\", y)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ⚖️ Feature Scaling\nscaler = StandardScaler()\nX = scaler.fit_transform(X)\njoblib.dump(scaler, \"scaler.pkl\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 🚀 Define Base and Meta Models\nxgb_reg = xgb.XGBRegressor(n_estimators=250, learning_rate=0.05, max_depth=6, subsample=0.8, random_state=42)\nlgb_reg = lgb.LGBMRegressor(n_estimators=250, learning_rate=0.05, max_depth=6, subsample=0.8, random_state=42)\ncb_reg = cb.CatBoostRegressor(iterations=250, learning_rate=0.05, depth=6, verbose=0, random_state=42)\nmeta_model = GradientBoostingRegressor(n_estimators=200, learning_rate=0.05, max_depth=4, random_state=42)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 🔁 5-Fold Cross Validation + OOF Stacking\nkf = KFold(n_splits=5, shuffle=True, random_state=42)\noof_preds = np.zeros((X.shape[0], 3))\n\nfor i, (train_idx, val_idx) in enumerate(kf.split(X)):\n    print(f\"📂 Fold {i+1}/5\")\n    X_train, X_val = X[train_idx], X[val_idx]\n    y_train, y_val = y[train_idx], y[val_idx]\n\n    xgb_reg.fit(X_train, y_train)\n    lgb_reg.fit(X_train, y_train)\n    cb_reg.fit(X_train, y_train)\n\n    oof_preds[val_idx, 0] = xgb_reg.predict(X_val)\n    oof_preds[val_idx, 1] = lgb_reg.predict(X_val)\n    oof_preds[val_idx, 2] = cb_reg.predict(X_val)\n\nmeta_model.fit(oof_preds, y)\njoblib.dump(meta_model, \"meta_model.pkl\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 📈 Evaluate on Hold-out Validation Set\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\nval_base_preds = np.vstack([\n    xgb_reg.predict(X_val),\n    lgb_reg.predict(X_val),\n    cb_reg.predict(X_val)\n]).T\nval_meta_preds = meta_model.predict(val_base_preds)\nval_meta_preds = np.clip(val_meta_preds, 0, 5)\ncorr, _ = pearsonr(y_val, val_meta_preds)\nprint(\"\\n📈 Pearson Correlation on Validation Set:\", corr)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 🔮 Stacked + Rank Averaged Prediction Function\ndef stacked_predict(X):\n    xgb_pred = xgb_reg.predict(X)\n    lgb_pred = lgb_reg.predict(X)\n    cb_pred = cb_reg.predict(X)\n    meta_input = np.vstack([xgb_pred, lgb_pred, cb_pred]).T\n    meta_pred = meta_model.predict(meta_input)\n\n    # Rank averaging for robustness\n    ranks = (rankdata(xgb_pred) + rankdata(lgb_pred) + rankdata(cb_pred)) / 3.0\n    ranks = MinMaxScaler((0, 5)).fit_transform(ranks.reshape(-1, 1)).flatten()\n\n    final = 0.5 * meta_pred + 0.5 * ranks\n    return np.clip(final, 0, 5)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 📤 Predict on Test Set\nsubmission = []\ntest_df = pd.read_csv(\"/kaggle/input/shl-intern-hiring-assessment/dataset/test.csv\")\nprint(\"\\n🧪 Predicting test data...\")\n\nfor _, row in tqdm(test_df.iterrows(), total=len(test_df)):\n    try:\n        path = f\"/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/{row['filename']}\"\n        feat = extract_features(path)\n        feat = scaler.transform([feat])\n        pred = stacked_predict(feat)[0]\n        submission.append([row['filename'], pred])\n    except Exception as e:\n        print(f\"❌ Error with {row['filename']}: {e}\")\n        submission.append([row['filename'], 0.0])\n\nsubmission_df = pd.DataFrame(submission, columns=['filename', 'label'])\nsubmission_df.to_csv(\"submission.csv\", index=False)\nprint(\"\\n✅ Submission saved as submission.csv\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}